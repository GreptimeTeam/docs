# Kafka Remote WAL æ–‡æ¡£ - User Guide

[Write-Ahead Logging](https://docs.greptime.com/contributor-guide/datanode/wal#introduction)ï¼ˆWALï¼‰æ˜¯ GreptimeDB ä¸­çš„ä¸€ä¸ªé‡è¦ç»„ä»¶ã€‚æ¯ä¸€ä¸ªæ•°æ®ä¿®æ”¹çš„æ“ä½œï¼Œéƒ½ä¼šä½œä¸ºä¸€ä¸ªæ—¥å¿—å­˜å‚¨åœ¨ WAL ä¸­ï¼Œä»¥ç¡®ä¿æ•°æ®åº“ä¸ä¼šä¸¢å¤±ç¼“å­˜åœ¨å†…å­˜ä¸­çš„æ•°æ®ã€‚

åœ¨ 0.5 ç‰ˆæœ¬ä¹‹å‰ï¼Œæˆ‘ä»¬ä½¿ç”¨åµŒå…¥å¼çš„Â [Raft Engine](https://www.pingcap.com/blog/raft-engine-a-log-structured-embedded-storage-engine-for-multi-raft-logs-in-tikv/)Â ä½œä¸º WAL çš„å­˜å‚¨å¼•æ“ã€‚è™½ç„¶åœ¨å®é™…éƒ¨ç½²æ—¶æˆ‘ä»¬å¯ä»¥å°† Raft Engine æŒ‚è½½åˆ°äº‘å­˜å‚¨ä¸Šï¼Œä½¿å¾—Â [RPO](https://en.wikipedia.org/wiki/Disaster_recovery#Recovery_Point_Objective)Â ä¸º 0ï¼Œä½†æ˜¯ç”±äºé‡æ–°æŒ‚è½½éœ€è¦æ—¶é—´ï¼Œå¯¼è‡´Â [RTO](https://en.wikipedia.org/wiki/Disaster_recovery#Recovery_Time_Objective)Â è¾ƒå¤§ã€‚å¦ä¸€æ–¹é¢ï¼ŒåµŒå…¥å¼çš„ Raft Engine ä¹Ÿæ— æ³•æ»¡è¶³å¤šç”¨æˆ·è®¢é˜…æ—¥å¿—çš„éœ€æ±‚ï¼Œè¿™ä½¿å¾— GreptimeDB æ— æ³•å®ç°[çƒ­å¤‡](https://en.wikipedia.org/wiki/Hot_spare)ã€region è¿ç§»ç­‰ç‰¹æ€§ã€‚

éšç€Â [0.5 ç‰ˆæœ¬](https://github.com/GreptimeTeam/greptimedb/releases/tag/v0.5.0)çš„å‘å¸ƒï¼Œæˆ‘ä»¬å¼€å§‹ä½¿ç”¨è¿œç¨‹å­˜å‚¨æœåŠ¡ä½œä¸º WAL çš„å­˜å‚¨å¼•æ“ï¼Œæˆ‘ä»¬ç§°è¿™æ ·çš„ WAL ä¸º Remote WALã€‚Â [Apache Kafka](https://kafka.apache.org/)Â è¢«å¹¿æ³›ç”¨äºæµå¤„ç†é¢†åŸŸï¼Œå®ƒè‡ªèº«çš„åˆ†å¸ƒå¼å®¹ç¾èƒ½åŠ›ï¼Œä»¥åŠåŸºäºÂ [Topic](https://www.conduktor.io/kafka/kafka-topics/)Â çš„è®¢é˜…æœºåˆ¶ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°æ»¡è¶³ GreptimeDB ç°é˜¶æ®µå¯¹ Remote WAL çš„éœ€æ±‚ï¼Œå› æ­¤æˆ‘ä»¬åœ¨ 0.5 ç‰ˆæœ¬ä¸­å¢åŠ  Apache Kafka ä½œä¸º WAL çš„å¯é€‰å­˜å‚¨å¼•æ“ã€‚

## å¦‚ä½•ä½¿ç”¨ Kafka Remote WAL

### Step 1: å¯åŠ¨ Kafka é›†ç¾¤

å¦‚æœæ‚¨å·²ç»éƒ¨ç½²äº† Kafka é›†ç¾¤ï¼Œæ‚¨å¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ã€‚ä½†è¯·æ‚¨ç•™æ„éƒ¨ç½²æ—¶è®¾å®šçš„Â [advertised listeners](https://www.conduktor.io/kafka/kafka-advertised-host-setting/)ï¼Œæ‚¨å°†åœ¨ Step 2 ä½¿ç”¨å®ƒã€‚



æˆ‘ä»¬æ¨èä½¿ç”¨Â [docker compose](https://docs.docker.com/compose/)Â å¯åŠ¨ Kafka é›†ç¾¤ã€‚Kafka æ”¯æŒÂ [KRaft](https://www.conduktor.io/kafka/kafka-kraft-mode/)Â å’ŒÂ [Zookeeper](https://www.conduktor.io/kafka/zookeeper-with-kafka/)Â ä¸¤ç§éƒ¨ç½²æ¨¡å¼ï¼Œæ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/confluentinc/kafka-images/blob/master/examples/confluent-server-kraft/docker-compose.yml)å’Œ[è¿™é‡Œ](https://github.com/conduktor/kafka-stack-docker-compose)åˆ†åˆ«æ‰¾åˆ° KRaft å’Œ Zookeeper ä¸¤ç§æ¨¡å¼çš„ docker compose è„šæœ¬ã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨ KRaft æ¨¡å¼éƒ¨ç½²ï¼Œæ­£å¦‚æˆ‘ä»¬ä½¿ç”¨çš„Â [docker-compose-standalone.yml](https://github.com/GreptimeTeam/greptimedb/blob/main/tests-integration/fixtures/kafka/docker-compose-standalone.yml)Â è„šæœ¬ã€‚ä¸ºäº†æ‚¨çš„æ–¹ä¾¿ï¼Œæˆ‘ä»¬å°†è¯¥è„šæœ¬çš„å†…å®¹æ”¾åœ¨ä¸‹æ–¹ã€‚

```toml
version: '3.8'
services:
  kafka:
    image: bitnami/kafka:3.6.0
    container_name: kafka
    ports:
      - 9092:9092
    environment:
      # KRaft settings
      KAFKA_KRAFT_CLUSTER_ID: Kmp-xkTnSf-WWXhWmiorDg
      KAFKA_ENABLE_KRAFT: "yes"
      KAFKA_CFG_NODE_ID: "1"
      KAFKA_CFG_PROCESS_ROLES: broker,controller
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@127.0.0.1:2181
      # Listeners
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:9092
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:2181
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_BROKER_ID: "1"
```

å¦‚éœ€è¦ä»¥å…¶ä»–æ–¹å¼å¯åŠ¨ Kafka é›†ç¾¤ï¼Œæ‚¨å¯ä»¥å‚è€ƒÂ [Kafka å®˜æ–¹æ–‡æ¡£](https://kafka.apache.org/quickstart)ã€‚



å‡è®¾æ‚¨å·²ç»å¯åŠ¨äº† Dockerï¼Œå¹¶ä¸”æ­£ç¡®è®¾ç½®äº† docker compose è„šæœ¬çš„è·¯å¾„ï¼Œæ‚¨å¯ä»¥åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œå¯åŠ¨ä¸€ä¸ªåŒ…å«å•ä¸ªÂ [broker](https://www.conduktor.io/kafka/kafka-brokers/)Â çš„ Kafka é›†ç¾¤ã€‚

```bash
docker compose -f docker-compose-standalone.yml up
```

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨å°†çœ‹åˆ°åŒ…å«å¦‚ä¸‹å†…å®¹çš„è¾“å‡ºï¼ˆæ—¥å¿—æ—¶é—´æˆ³å°†ä¼šä¸åŒï¼‰ï¼š

```bash
...
kafka  | [2024-01-11 07:06:55,518] INFO KafkaConfig values:
kafka  |         advertised.listeners = PLAINTEXT://127.0.0.1:9092
...
kafka  | [2024-01-11 07:06:55,554] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
```

### Step 2: é…ç½® GreptimeDB

ç›®å‰ï¼ŒGreptimeDB é»˜è®¤ä½¿ç”¨ Raft Engine ä½œä¸º WAL çš„å­˜å‚¨å¼•æ“ã€‚å½“ä½¿ç”¨ Kafka Remote WAL æ—¶ï¼Œæ‚¨éœ€è¦é€šè¿‡é…ç½®æ–‡ä»¶æ‰‹åŠ¨æŒ‡å®š Kafka ä¸º WAL çš„å­˜å‚¨å¼•æ“ã€‚

#### Standalone æ¨¡å¼

æˆ‘ä»¬å°†ä¸€äº›éœ€è¦æ‚¨ç‰¹åˆ«å…³æ³¨çš„ Kafka Remote WAL çš„é…ç½®é¡¹æ‘˜å½•å¦‚ä¸‹ã€‚å…³äºå®Œæ•´çš„é…ç½®é¡¹ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹[è¿™é‡Œ](https://github.com/GreptimeTeam/greptimedb/blob/d061bf3d07897ea785924eda8b947f9b18d44646/config/standalone.example.toml#L83-L124)ã€‚

```toml
[wal]
provider = "kafka"
broker_endpoints = ["127.0.0.1:9092"]
replication_factor = 1
max_batch_size = "1MB"
```

å„ä¸ªé…ç½®é¡¹çš„å«ä¹‰ä¸ºï¼š

- `provider`: æŒ‡å®š WAL å­˜å‚¨å¼•æ“ã€‚åº”è®¾ç½®ä¸ºÂ `"kafka"`Â ï¼Œä»¥æŒ‡å®šä½¿ç”¨ Kafka Remote WALã€‚
- `broker_endpoints`: æŒ‡å®š Kafka é›†ç¾¤æ‰€æœ‰ brokers çš„ advertised listenersã€‚æ‚¨éœ€è¦æ ¹æ® docker compose è„šæœ¬ä¸­æŒ‡å®šçš„Â `KAFKA_CFG_ADVERTISED_LISTENERS`Â æ¥é…ç½®è¯¥é¡¹ã€‚å¦‚æ‚¨é€šè¿‡å…¶ä»–æ–¹å¼éƒ¨ç½² Kafka é›†ç¾¤ï¼Œæ‚¨éœ€è¦æ ¹æ®æ‚¨åœ¨éƒ¨ç½²æ—¶è®¾ç½®çš„ advertised listeners æ¥é…ç½®è¯¥é¡¹ã€‚å¦‚æœªæ˜ç¡®é…ç½®ï¼Œåˆ™é»˜è®¤ä¸ºÂ `["127.0.0.1:9092"]`ã€‚
- `replication_factor`: æ¯ä¸ªÂ [partition](https://www.conduktor.io/kafka/kafka-topic-replication/)Â çš„æ•°æ®ä¼šå¤åˆ¶åˆ°æŒ‡å®šæ•°é‡çš„ brokers ä¸Šã€‚è¯¥é…ç½®é¡¹çš„å€¼å¿…é¡»å¤§äº 0ï¼Œä¸”ä¸å¤§äº brokers çš„æ•°é‡ã€‚
- `max_batch_size`: æˆ‘ä»¬ä¼šé™åˆ¶ä¸€æ‰¹æ¬¡ä¼ è¾“çš„ log batch çš„æ€»å¤§å°ä¸è¶…è¿‡è¯¥é…ç½®é¡¹æ‰€è®¾å®šçš„å€¼ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒKafka é»˜è®¤ä¼šæ‹’ç»è¶…è¿‡ 1MB çš„ logï¼Œæ‰€ä»¥æˆ‘ä»¬å»ºè®®æ‚¨å°†è¯¥é…ç½®é¡¹è®¾å®šä¸ºä¸è¶…è¿‡ 1MBã€‚å¦‚æ‚¨ç¡®å®éœ€è¦è°ƒå¤§è¯¥é…ç½®é¡¹ï¼Œæ‚¨å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://www.conduktor.io/kafka/how-to-send-large-messages-in-apache-kafka/)ä»¥äº†è§£å¦‚ä½•é…ç½® Kafkaã€‚

#### Distributed æ¨¡å¼

å¯¹äºåˆ†å¸ƒå¼æ¨¡å¼ï¼ŒKafka Remote WAL çš„é…ç½®é¡¹åˆ†å¸ƒåœ¨ metasrv å’Œ datanode çš„é…ç½®æ–‡ä»¶ä¸­ã€‚ä¸å•æœºæ¨¡å¼ç›¸æ¯”ï¼Œé…ç½®é¡¹çš„åç§°ã€å«ä¹‰ã€é»˜è®¤å€¼å‡ä¿æŒä¸€è‡´ã€‚æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/GreptimeTeam/greptimedb/blob/d061bf3d07897ea785924eda8b947f9b18d44646/config/metasrv.example.toml#L46-L78)æŸ¥çœ‹ metasrv çš„ç¤ºä¾‹é…ç½®é¡¹ï¼Œä»¥åŠåœ¨[è¿™é‡Œ](https://github.com/GreptimeTeam/greptimedb/blob/d061bf3d07897ea785924eda8b947f9b18d44646/config/datanode.example.toml#L40-L60)æŸ¥çœ‹ datanode çš„ç¤ºä¾‹é…ç½®é¡¹ã€‚

### Step 3:Â å¯åŠ¨ GreptimeDB

#### Standalone æ¨¡å¼

å‡è®¾æ‚¨æ­£ç¡®è®¾ç½®äº† GreptimeDB äºŒè¿›åˆ¶æ–‡ä»¶çš„è·¯å¾„ï¼Œæ‚¨å¯ä»¥åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œä»¥å¯åŠ¨ä¸€ä¸ª GreptimeDB å•ä¾‹ï¼Œå¹¶è®©å…¶ä½¿ç”¨æ‚¨åœ¨ Step 2 ä¸­æ‰€è®¾å®šçš„é…ç½®é¡¹ã€‚

```bash
./greptime standalone start -c config/standalone.example.toml
```

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨å°†åœ¨ç»ˆç«¯ä¸­çœ‹åˆ°åŒ…å«å¦‚ä¸‹å†…å®¹çš„æ—¥å¿—ï¼ˆæ‚¨æ‰€çœ‹åˆ°çš„å†…å®¹å¯èƒ½ç”±äº GreptimeDB çš„ç‰ˆæœ¬å˜åŒ–è€Œç•¥æœ‰å·®å¼‚ï¼‰ï¼š

```bash
...
INFO rskafka::connection: Establishing new connection url="127.0.0.1:9092"
INFO rskafka::connection::topology: New broker broker=1 new=127.0.0.1:9092
INFO rskafka::client::controller: Creating new controller broker connection
INFO rskafka::connection: Establishing new connection broker=1 url="127.0.0.1:9092"
INFO common_meta::wal::kafka::topic_manager: Successfully created topic greptimedb_wal_topic_0
INFO rskafka::client::partition: Creating new partition-specific broker connection topic=greptimedb_wal_topic_0 partition=0
INFO rskafka::client::partition: Detected leader topic=greptimedb_wal_topic_0 partition=0 leader=1 metadata_mode=CachedArbitrary
...
INFO frontend::instance: Starting service: MYSQL_SERVER
INFO servers::server: Starting MYSQL_SERVER at 127.0.0.1:4002
INFO servers::server: MySQL server started at 127.0.0.1:4002
...
```

æ³¨æ„ï¼Œå¦‚æ‚¨åœ¨ Kafka é›†ç¾¤å­˜ç»­çš„æƒ…å†µä¸‹ï¼Œå¤šæ¬¡æ‹‰èµ· GreptimeDBï¼Œæ‚¨çœ‹åˆ°çš„å…³äº Kafka çš„æ—¥å¿—å¯èƒ½æœ‰æ‰€ä¸åŒã€‚

#### Distributed æ¨¡å¼

æˆ‘ä»¬æä¾›äº†Â [gtctl](https://docs.greptime.com/user-guide/operations/gtctl#gtctl)Â å·¥å…·ä»¥è¾…åŠ©æ‚¨å¿«é€Ÿæ‹‰èµ·ä¸€ä¸ª GreptimeDB é›†ç¾¤ã€‚ä¸ºäº†ä¾¿äºæ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨ gtctl å¯åŠ¨ä¸€ä¸ªÂ [bare-metal](https://docs.greptime.com/user-guide/operations/gtctl#bare-metal)Â é›†ç¾¤ï¼ŒåŒ…å« 1 ä¸ª metasrvã€1 ä¸ª frontendã€3 ä¸ª datanodesã€‚ä¸ºæ­¤ï¼Œæ‚¨éœ€è¦å‡†å¤‡å¥½ gtctl æ‰€éœ€çš„é…ç½®æ–‡ä»¶Â `cluster.yml`ã€‚ä¸€ä¸ªç¤ºä¾‹é…ç½®æ–‡ä»¶çš„å†…å®¹å¦‚ä¸‹ï¼š

```toml
cluster:
  name: mycluster
  artifact:
    local: "/path/to/greptime"
  frontend:
    replicas: 1
  datanode:
    replicas: 3
    rpcAddr: 0.0.0.0:14100
    mysqlAddr: 0.0.0.0:14200
    httpAddr: 0.0.0.0:14300
    config: '/path/to/datanode.example.toml'
  meta:
    replicas: 1
    storeAddr: 127.0.0.1:2379
    serverAddr: 0.0.0.0:3002
    httpAddr: 0.0.0.0:14001
    config: '/path/to/metasrv.example.toml'
etcd:
  artifact:
    local: "/path/to/etcd"
```

å…¶ä¸­ï¼ŒÂ `metasrv.example.toml`Â å’ŒÂ `datanode.example.toml`Â åˆ†åˆ«è¡¨ç¤º metasrv å’Œ datanode çš„é…ç½®æ–‡ä»¶çš„åç§°ã€‚æ‚¨éœ€è¦æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹ç¤ºä¾‹æ–‡ä»¶ä¸­ä»¥Â `/path/to/`Â ä¸ºå‰ç¼€çš„æ‰€æœ‰é…ç½®é¡¹ã€‚



å‡è®¾æ‚¨å·²ç»æ­£ç¡®å®‰è£…äº† gtctlï¼Œå¹¶ä¸”å·²ç»æ­£ç¡®é…ç½®å¥½Â `cluster.yml`Â æ–‡ä»¶çš„å†…å®¹å’Œè·¯å¾„ï¼Œæ‚¨å¯ä»¥åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œä»¥å¯åŠ¨ä¸€ä¸ªåä¸ºÂ `mycluster`Â çš„ GreptimeDB é›†ç¾¤ï¼š

```bash
gtctl cluster create mycluster --bare-metal --config cluster.yaml
```

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨å°†åœ¨ç»ˆç«¯ä¸­çœ‹åˆ°åŒ…å«å¦‚ä¸‹å†…å®¹çš„æ—¥å¿—ï¼ˆæ‚¨æ‰€çœ‹åˆ°çš„å†…å®¹å¯èƒ½ç”±äº gtctl çš„ç‰ˆæœ¬å˜åŒ–è€Œç•¥æœ‰å·®å¼‚ï¼‰ï¼š

```bash
Creating GreptimeDB cluster 'mycluster' on bare-metal environment...
 âœ“ Installing etcd cluster successfully ğŸ‰
 âœ“ Installing GreptimeDB cluster successfully ğŸ‰
Now you can use the following commands to access the GreptimeDB cluster:
MySQL >
$ mysql -h 127.0.0.1 -P 4002
PostgreSQL >
$ psql -h 127.0.0.1 -p 4003 -d public
Thank you for using GreptimeDB! Check for more information on
autolinkhttps://greptime.comautolink
. ğŸ˜Š
Invest in Data, Harvest over Time. ğŸ”‘
The cluster(pid=33587, version=unknown) is running in bare-metal mode now...
To view dashboard by accessing: http://localhost:4000/dashboard/
```

é»˜è®¤é…ç½®ä¸‹ï¼Œæ‚¨å¯ä»¥åœ¨Â `~/.gtctl/mycluster/logs`Â ç›®å½•ä¸‹æ‰¾åˆ°Â `mycluster`Â é›†ç¾¤ä¸­å„ä¸ªç»„ä»¶çš„æ—¥å¿—ã€‚ä¾‹å¦‚åœ¨Â `~/.gtctl/mycluster/logs/metasrv.0/log`Â æ—¥å¿—æ–‡ä»¶ä¸­ï¼Œæ‚¨å°†æ‰¾åˆ°ä¸Â [Standalone æ¨¡å¼](https://greptime.feishu.cn/wiki/FtqvwppGLi8tXJkDeslcPNcVn2f#Ko2qdSiJMoQWrzxyeSncW6ppn6e)ç±»ä¼¼çš„å†…å®¹ã€‚

## éªŒè¯ Kafka Remote WAL çš„æœ‰æ•ˆæ€§

éªŒè¯æµç¨‹å¯å½’ç»“ä¸ºï¼š

- åœ¨ GreptimeDB é›†ç¾¤ä¸­åˆ›å»ºä¸€å¼ è¡¨ï¼Œå¹¶å†™å…¥ä¸€å®šé‡çš„æ•°æ®ã€‚
- æ‰§è¡Œ Query ä»¥éªŒè¯æ•°æ®è¢«æˆåŠŸå†™å…¥ã€‚
- é‡å¯ GreptimeDB é›†ç¾¤ï¼Œå†æ‰§è¡Œ Query ä»¥éªŒè¯æ•°æ®è¢«æ­£ç¡®æ¢å¤ã€‚



æˆ‘ä»¬åœ¨æ¼”ç¤ºä¸­ä½¿ç”¨Â [MySQL Shell](https://dev.mysql.com/doc/mysql-shell/8.0/en/mysqlsh.html)Â ä½œä¸ºè¿æ¥ GreptimeDB é›†ç¾¤çš„å®¢æˆ·ç«¯ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ‚¨æ‰€å–œçˆ±çš„å…¶å®ƒå®¢æˆ·ç«¯ã€‚æˆ‘ä»¬åœ¨æ¼”ç¤ºä¸­ä½¿ç”¨çš„ SQL å‡æ¥æºäºæˆ–ä¿®æ”¹è‡ªÂ [Cluster æ–‡æ¡£](https://docs.greptime.cn/user-guide/cluster)ã€‚



å‡è®¾æ‚¨å·²ç»è¿æ¥ä¸Š GreptimeDB é›†ç¾¤ï¼Œæ‚¨å¯ä»¥åœ¨å®¢æˆ·ç«¯å†…æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åˆ›å»ºä¸€å¼ è¡¨ï¼š

```sql
CREATE TABLE dist_table(
    ts TIMESTAMP DEFAULT current_timestamp(),
    n STRING,
    row_num INT,
    PRIMARY KEY(n),
    TIME INDEX (ts)
)
PARTITION BY RANGE COLUMNS (n) (
    PARTITION r0 VALUES LESS THAN ("f"),
    PARTITION r1 VALUES LESS THAN ("z"),
    PARTITION r2 VALUES LESS THAN (MAXVALUE),
)
engine=mito;
```

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥å†™å…¥ä¸€å®šé‡çš„æ•°æ®ï¼š

```sql
INSERT INTO dist_table(n, row_num) VALUES ("a", 1);
INSERT INTO dist_table(n, row_num) VALUES ("b", 2);
INSERT INTO dist_table(n, row_num) VALUES ("c", 3);
INSERT INTO dist_table(n, row_num) VALUES ("d", 4);
INSERT INTO dist_table(n, row_num) VALUES ("e", 5);
INSERT INTO dist_table(n, row_num) VALUES ("f", 6);
INSERT INTO dist_table(n, row_num) VALUES ("g", 7);
INSERT INTO dist_table(n, row_num) VALUES ("h", 8);
INSERT INTO dist_table(n, row_num) VALUES ("i", 9);
INSERT INTO dist_table(n, row_num) VALUES ("j", 10);
INSERT INTO dist_table(n, row_num) VALUES ("k", 11);
INSERT INTO dist_table(n, row_num) VALUES ("l", 12);
```

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥æŸ¥è¯¢æ•°æ®ï¼š

```sql
SELECT * FROM dist_table;
```

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨å°†çœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼ˆ`ts`Â åˆ—çš„å†…å®¹å°†ä¼šä¸åŒï¼‰ï¼š

```sql
+----------------------------+---+---------+
| ts                         | n | row_num |
+----------------------------+---+---------+
| 2024-01-19 07:33:34.123000 | a |       1 |
| 2024-01-19 07:33:34.128000 | b |       2 |
| 2024-01-19 07:33:34.130000 | c |       3 |
| 2024-01-19 07:33:34.131000 | d |       4 |
| 2024-01-19 07:33:34.133000 | e |       5 |
| 2024-01-19 07:33:34.134000 | f |       6 |
| 2024-01-19 07:33:34.135000 | g |       7 |
| 2024-01-19 07:33:34.136000 | h |       8 |
| 2024-01-19 07:33:34.138000 | i |       9 |
| 2024-01-19 07:33:34.140000 | j |      10 |
| 2024-01-19 07:33:34.141000 | k |      11 |
| 2024-01-19 07:33:34.907000 | l |      12 |
+----------------------------+---+---------+
12 rows in set (0.0346 sec)
```

ç”±äºæˆ‘ä»¬åœ¨å»ºè¡¨æ—¶æŒ‡å®šäº† partition è§„åˆ™ï¼Œmetasrv ä¼šå°†è¯¥è¡¨çš„ regions å‡åŒ€åˆ†é…åˆ°é›†ç¾¤ä¸­çš„ datanodes ä¸Šã€‚æŸ¥çœ‹ datanode 0 çš„æ—¥å¿—æ–‡ä»¶Â `~/.gtctl/mycluster/logs/datanode.0/log`ï¼Œæ‚¨å°†çœ‹åˆ°ç±»ä¼¼å¦‚ä¸‹å†…å®¹çš„æ—¥å¿—ï¼š

```bash
INFO mito2::worker::handle_create: A new region created, region: RegionMetadata { column_metadatas: [[ts TimestampMillisecond not null default=Function("current_timestamp()") Timestamp 0], [n String null Tag 1], [row_num Int32 null Field 2]], time_index: 0, primary_key: [1], region_id: 4398046511105(1024, 1), schema_version: 0 }
INFO rskafka::client::partition: Creating new partition-specific broker connection topic=greptimedb_wal_topic_22 partition=0
INFO rskafka::client::partition: Detected leader topic=greptimedb_wal_topic_22 partition=0 leader=1 metadata_mode=CachedArbitrary
INFO rskafka::connection: Establishing new connection broker=1 url="127.0.0.1:9092"
```

è¿™äº›æ—¥å¿—è¯´æ˜ï¼Œæˆ‘ä»¬æ‰€åˆ›å»ºçš„Â `dist_table`Â è¡¨çš„æŸä¸ª region è¢«åˆ†é…åˆ°äº† datanode 0 ä¸Šï¼Œä¸”å®ƒçš„æ—¥å¿—è¢«å†™å…¥åˆ°äº†åä¸ºÂ `greptimedb_wal_topic_22`Â çš„Kafka topicã€‚ç”±äº topic åˆ†é…çš„é€»è¾‘å…·æœ‰ä¸€å®šçš„éšæœºæ€§ï¼Œæ‚¨å¯èƒ½çœ‹åˆ°ä¸ä¸€æ ·çš„ topic åç§°ã€‚



ç°åœ¨æˆ‘ä»¬éªŒè¯äº†æ•°æ®å·²ç»æˆåŠŸå†™å…¥ï¼Œæˆ‘ä»¬ kill æ‰ datanode 0ï¼Œå†é‡æ–°æ‹‰èµ·å®ƒã€‚

åœ¨ç»ˆç«¯ä¸­æ‰§è¡ŒÂ `ps | grep node-id=0`Â å‘½ä»¤ï¼Œæ‚¨å°†çœ‹åˆ°ç±»ä¼¼å¦‚ä¸‹å†…å®¹çš„è¾“å‡ºã€‚æˆ‘ä»¬éœ€è¦ä»å…¶ä¸­æ‰¾åˆ° datanode 0 æ‰€å±çš„ pidï¼Œä»¥åŠè®°å½• gtctl å¯åŠ¨ datanode 0 æ—¶æ‰§è¡Œçš„å…·ä½“å‘½ä»¤ã€‚

```bash
17332 ttys002    0:01.76 /Users/sunflower/greptimedb/target/debug/greptime --log-level=info datanode start --node-id=0 --metasrv-addr=0.0.0.0:3002 --rpc-addr=0.0.0.0:14100 --http-addr=0.0.0.0:14300 --data-home=/Users/sunflower/.gtctl/mycluster/data/datanode.0/home -c=/Users/sunflower/greptimedb/config/datanode.example.toml
```

ä½¿ç”¨Â `kill`Â å‘½ä»¤å¼ºåˆ¶ç»ˆæ­¢ datanode 0ï¼ˆæ‚¨éœ€è¦æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹ datanode 0 çš„ pidï¼‰ï¼š

```bash
kill -9 17332
```

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥å†æ¬¡æŸ¥è¯¢æ•°æ®ï¼š

```sql
SELECT * FROM dist_table;
```

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨å°†çœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼š

```sql
ERROR: 1815 (HY000): Internal error: 1003
```

è¿™è¯´æ˜æˆ‘ä»¬æˆåŠŸç»ˆæ­¢äº† datanode 0ï¼Œå¯¼è‡´æŸ¥è¯¢æ— æ³•è¢« GreptimeDB é›†ç¾¤æ­£å¸¸å¤„ç†ï¼Œä»¥è‡´å‡ºç°é”™è¯¯ã€‚



ç°åœ¨ï¼Œæˆ‘ä»¬æ‰§è¡Œä¹‹å‰æ‰€è®°å½•çš„å‘½ä»¤ä»¥é‡æ–°æ‹‰èµ· datanode 0ï¼ˆæ‚¨éœ€è¦æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹è¯¥å‘½ä»¤ï¼‰ã€‚æ³¨æ„ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä¼šè®© datanode 0 è¿è¡Œåœ¨ä¸€ä¸ªå‰å°ç»ˆç«¯ä¸­ï¼Œå®ƒçš„æ—¥å¿—ä¹Ÿä¼šå‡ºç°åœ¨è¯¥ç»ˆç«¯ä¸­ã€‚

```bash
./greptime --log-level=info datanode start --node-id=0 --metasrv-addr=0.0.0.0:3002 --rpc-addr=0.0.0.0:14100 --http-addr=0.0.0.0:14300 --data-home=/Users/sunflower/.gtctl/mycluster/data/datanode.0/home -c=/Users/sunflower/greptimedb/config/datanode.example.toml
```

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥å†æ¬¡æŸ¥è¯¢æ•°æ®ï¼š

```sql
SELECT * FROM dist_table;
```

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨å°†çœ‹åˆ°å¦‚ä¸‹è¾“å‡ºã€‚è¿™è¯´æ˜ datanode 0 è¢«æˆåŠŸæ‹‰èµ·ï¼Œä¸”æ­£ç¡®æ¢å¤äº†æ•°æ®ã€‚

```sql
+----------------------------+---+---------+
| ts                         | n | row_num |
+----------------------------+---+---------+
| 2024-01-19 07:33:34.123000 | a |       1 |
| 2024-01-19 07:33:34.128000 | b |       2 |
| 2024-01-19 07:33:34.130000 | c |       3 |
| 2024-01-19 07:33:34.131000 | d |       4 |
| 2024-01-19 07:33:34.133000 | e |       5 |
| 2024-01-19 07:33:34.134000 | f |       6 |
| 2024-01-19 07:33:34.135000 | g |       7 |
| 2024-01-19 07:33:34.136000 | h |       8 |
| 2024-01-19 07:33:34.138000 | i |       9 |
| 2024-01-19 07:33:34.140000 | j |      10 |
| 2024-01-19 07:33:34.141000 | k |      11 |
| 2024-01-19 07:33:34.907000 | l |      12 |
+----------------------------+---+---------+
12 rows in set (0.0346 sec)
```

åŒæ—¶ï¼Œåœ¨ datanode 0 çš„å‰å°ç»ˆç«¯ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°ç±»ä¼¼å¦‚ä¸‹å†…å®¹çš„æ—¥å¿—ï¼š

```bash
INFO mito2::worker::handle_open: Try to open region 4398046511105(1024, 1)
INFO mito2::region::opener: Start replaying memtable at flushed_entry_id + 1 1 for region 4398046511105(1024, 1)
INFO rskafka::client::partition: Creating new partition-specific broker connection topic=greptimedb_wal_topic_22 partition=0
INFO rskafka::client::partition: Detected leader topic=greptimedb_wal_topic_22 partition=0 leader=1 metadata_mode=CachedArbitrary
INFO rskafka::connection: Establishing new connection broker=1 url="127.0.0.1:9092"
INFO mito2::region::opener: Replay WAL for region: 4398046511105(1024, 1), rows recovered: 4, last entry id: 7
INFO mito2::worker::handle_open: Region 4398046511105(1024, 1) is opened
INFO datanode::region_server: Region 4398046511105(1024, 1) is registered to engine mito
INFO datanode::datanode: all regions are opened
```

è¿™äº›æ—¥å¿—è¯´æ˜ï¼Œdatanode 0 åœ¨é‡å¯æ—¶ä» Kafka æ‹‰å–äº†å¿…éœ€çš„ logsï¼Œä»¥é‡å»ºÂ `dist_table`Â è¡¨çš„æŸä¸ª region çš„çŠ¶æ€ã€‚



é€šè¿‡ä»¥ä¸Šæ¼”ç¤ºï¼Œæˆ‘ä»¬åŸºæœ¬éªŒè¯äº† Kafka Remote WAL çš„æœ‰æ•ˆæ€§ã€‚éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨æ¼”ç¤ºæ—¶ä¸ºäº†æ–¹ä¾¿å°†æ‰€æœ‰ç»„ä»¶è¿è¡Œåœ¨æœ¬åœ°æœºå™¨ä¸Šã€‚ç”±äºç»„ä»¶é—´çš„é€šä¿¡å®Œå…¨åŸºäºç½‘ç»œï¼Œå³ä½¿ç»„ä»¶åˆ†å¸ƒå¼åœ°è¿è¡Œåœ¨ä¸åŒæœºå™¨ä¸Šï¼ŒKafka Remote WAL çš„æœ‰æ•ˆæ€§ä¹Ÿä¸ä¼šå—åˆ°å½±å“ã€‚
